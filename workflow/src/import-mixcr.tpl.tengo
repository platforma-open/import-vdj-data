ll := import("@platforma-sdk/workflow-tengo:ll")
self := import("@platforma-sdk/workflow-tengo:tpl.light")
pConstants := import("@platforma-sdk/workflow-tengo:pframes.constants")
smart := import("@platforma-sdk/workflow-tengo:smart")
slices := import("@platforma-sdk/workflow-tengo:slices")
maps := import("@platforma-sdk/workflow-tengo:maps")
assets := import("@platforma-sdk/workflow-tengo:assets")
exec := import("@platforma-sdk/workflow-tengo:exec")
pt := import("@platforma-sdk/workflow-tengo:pt")
sets := import("@platforma-sdk/workflow-tengo:sets")
json := import("json")

self.defineOutputs("tsv", "stats", "tsvForSingleCell")

self.body(func(inputs) {
    inputFiles := inputs[pConstants.VALUE_FIELD_NAME]
    columnsInfo := inputs.columnsInfo
    chains := inputs.chains

    wf := pt.workflow().mem("8GiB").cpu(4)

    dataFrames := []
    for key, file in inputFiles.inputs() {
        dataFrames = append(dataFrames, wf.frame(file, {
            xsvType: "tsv",
            id: "table_" + key,
            inferSchema: false
        }))
    }

    if len(dataFrames) == 0 {
        ll.panic("no input files found")
    }

    df := undefined
    if len(dataFrames) > 1 { df = pt.concat(dataFrames) } else { df = dataFrames[0] }

    // Rename original columns to canonical IDs used downstream
    renameExpressions := []
    for canonical, original in columnsInfo.columnMapping {
        if original != undefined {
            // Avoid self-alias which can create duplicate column names
            if canonical != original {
                renameExpressions = append(renameExpressions, pt.col(original).alias(canonical))
            }
        }
    }
    df = df.withColumns(renameExpressions...)

    // Add vdj aa and nt columns if present in columnsInfo.propertyColumns
    hasFr4Nt := columnsInfo.columnMapping["fr4-nt"] != undefined
    hasFr4Aa := columnsInfo.columnMapping["fr4-aa"] != undefined
    hasVdjNt := columnsInfo.columnMapping["vdj-nt"] != undefined
    hasVdjAa := columnsInfo.columnMapping["vdj-aa"] != undefined
    nt_cols := ["fr1-nt", "cdr1-nt", "fr2-nt", "cdr2-nt", "fr3-nt", "cdr3-nt"]
    if hasFr4Nt { nt_cols = append(nt_cols, "fr4-nt") }
    aa_cols := ["fr1-aa", "cdr1-aa", "fr2-aa", "cdr2-aa", "fr3-aa", "cdr3-aa"]
    if hasFr4Aa { aa_cols = append(aa_cols, "fr4-aa") }

    for prop in columnsInfo.propertyColumns {
        isVdjNt := false
        isVdjAa := false
        if prop.spec != undefined && prop.spec.domain != undefined {
            isVdjNt = prop.spec.domain["pl7.app/vdj/feature"] == "VDJRegion"
            isVdjAa = prop.spec.domain["pl7.app/vdj/feature"] == "VDJRegionInFrame"
        }

        if isVdjNt && !hasVdjNt {
            nt_exprs := slices.map(nt_cols, func(c) { return pt.col(c) })
            df = df.withColumns(pt.concatStr(nt_exprs, { delimiter: "" }).alias(prop.column))
        }
        if isVdjAa && !hasVdjAa {
            aa_exprs := slices.map(aa_cols, func(c) { return pt.col(c) })
            df = df.withColumns(pt.concatStr(aa_exprs, { delimiter: "" }).alias(prop.column))
        }
    }

    // Remove rows where any sequence column contains "region_not_covered"
    seqCols := nt_cols + aa_cols + ["vdj-nt", "vdj-aa"]
    invalidExpr := undefined
    for col in seqCols {
        if columnsInfo.columnMapping[col] != undefined {
            cond := pt.col(col).strContains("region_not_covered", { literal: true })
            if invalidExpr == undefined { invalidExpr = cond } else { invalidExpr = invalidExpr.or(cond) }
        }
    }
    if invalidExpr != undefined {
        df = df.filter(invalidExpr.not())
    }

    // Ensure allele columns presence according to rules:
    // If any of bestXHit/allXHits/allXHitsWithScore exist in input, create x-allele.
    // Value equals bestXHit when available; otherwise set to empty string.
    alleleExpressions := []
    ensureAlleleCol := func(prefix) {
        keyBest := prefix + "-allele"
        keyAllWS := "all" + (prefix == "v" ? "V" : prefix == "d" ? "D" : prefix == "j" ? "J" : "C") + "HitsWithScore"
        keyAll := "all" + (prefix == "v" ? "V" : prefix == "d" ? "D" : prefix == "j" ? "J" : "C") + "Hits"
        hasAny := columnsInfo.columnMapping[keyBest] != undefined || columnsInfo.columnMapping[keyAllWS] != undefined || columnsInfo.columnMapping[keyAll] != undefined
        if hasAny {
            if columnsInfo.columnMapping[keyBest] != undefined {
                // Already renamed above; nothing to add
                return
            }
            // Fallback: derive allele value from available lists or best gene
            // Order: allXHitsWithScore (first, strip parens) > allXHits (first) > bestXGene > ""
            firstItem := func(col) { return pt.col(col).strReplace(",.*$", "", { replaceAll: true }) }
            stripParens := func(expr) { return expr.strReplace("\\(.*$", "", { replaceAll: true }) }
            bestGene := prefix + "-gene"
            if columnsInfo.columnMapping[keyAllWS] != undefined {
                alleleExpressions = append(alleleExpressions, stripParens(firstItem(keyAllWS)).alias(keyBest))
            } else if columnsInfo.columnMapping[keyAll] != undefined {
                alleleExpressions = append(alleleExpressions, firstItem(keyAll).alias(keyBest))
            } else if columnsInfo.columnMapping[bestGene] != undefined {
                alleleExpressions = append(alleleExpressions, pt.col(bestGene).alias(keyBest))
            } else {
                alleleExpressions = append(alleleExpressions, pt.lit("").alias(keyBest))
            }
        }
    }
    ensureAlleleCol("v")
    ensureAlleleCol("d")
    ensureAlleleCol("j")
    ensureAlleleCol("c")
    if len(alleleExpressions) > 0 {
        df = df.withColumns(alleleExpressions...)
    }

    // bestXGene derivation: only reference columns that exist in header
    // Order: bestXGene (if present) > bestXHit (strip allele) > allXHitsWithScore (first, strip) > allXGenes (first) > allXHits (first, strip) > ""
    deriveBestGene := func(prefix) {
        bestGene := prefix + "-gene"
        bestHit := prefix + "-allele"
        allWithScore := "all" + (prefix == "v" ? "V" : prefix == "d" ? "D" : prefix == "j" ? "J" : "C") + "HitsWithScore"
        allHits := "all" + (prefix == "v" ? "V" : prefix == "d" ? "D" : prefix == "j" ? "J" : "C") + "Hits"
        allGenes := "all" + (prefix == "v" ? "V" : prefix == "d" ? "D" : prefix == "j" ? "J" : "C") + "Genes"

        firstItem := func(col) { return pt.col(col).strReplace(",.*$", "", { replaceAll: true }) }
        stripParens := func(expr) { return expr.strReplace("\\(.*$", "", { replaceAll: true }) }
        stripAllele := func(expr) { return expr.strReplace("\\*.*$", "", { replaceAll: true }) }

        hasBestGene := columnsInfo.columnMapping[bestGene] != undefined
        hasBestHit := columnsInfo.columnMapping[bestHit] != undefined
        hasAllWithScore := columnsInfo.columnMapping[allWithScore] != undefined
        hasAllGenes := columnsInfo.columnMapping[allGenes] != undefined
        hasAllHits := columnsInfo.columnMapping[allHits] != undefined

        if hasBestGene {
            return pt.col(bestGene).alias(bestGene)
        }
        if hasBestHit {
            return stripAllele(pt.col(bestHit)).alias(bestGene)
        }
        if hasAllWithScore {
            return stripAllele(stripParens(firstItem(allWithScore))).alias(bestGene)
        }
        if hasAllGenes {
            return firstItem(allGenes).alias(bestGene)
        }
        if hasAllHits {
            return stripAllele(firstItem(allHits)).alias(bestGene)
        }
        return pt.lit("").alias(bestGene)
    }

    // Note: We now synthesize allele columns when bestXHit is missing using lists or best gene

    // Ensure best gene columns exist
    df = df.withColumns(
        deriveBestGene("v"),
        deriveBestGene("d"),
        deriveBestGene("j"),
        deriveBestGene("c")
    )

    // Allele columns: we only keep/use them if bestXHit was present in the header (renamed to x-allele above).
    // If bestXHit is absent, do not synthesize allele columns from other lists.

    // Drop rows with empty v/j genes
    for col in ["j-gene", "v-gene"] {
        df = df.filter(pt.col(col).isNotNull().and(pt.col(col).neq("")))
    }

    // Determine productivity from AA CDR3 (MiXCR behavior)
    df = df.withColumns(
        pt.col("cdr3-aa").isNotNull().
            and(pt.col("cdr3-aa").neq("")).
            and(pt.col("cdr3-aa").strContains("*", {literal: true}).not()).
            and(pt.col("cdr3-aa").strContains("_", {literal: true}).not()).
            alias("is-productive")
    )

    // Build clonotypeKey with robust fallback if infer failed to populate key columns
    // Preferred order: vdj-nt; else cdr3-nt; else cdr3-aa; always add v-gene/j-gene if present; c-gene optional
    inferKeyColumns := func() {
        cols := []
        if columnsInfo.columnMapping["vdj-nt"] != undefined { cols = append(cols, "vdj-nt") }
        if len(cols) == 0 && columnsInfo.columnMapping["cdr3-nt"] != undefined { cols = append(cols, "cdr3-nt") }
        if len(cols) == 0 && columnsInfo.columnMapping["cdr3-aa"] != undefined { cols = append(cols, "cdr3-aa") }
        if columnsInfo.columnMapping["v-gene"] != undefined { cols = append(cols, "v-gene") }
        if columnsInfo.columnMapping["j-gene"] != undefined { cols = append(cols, "j-gene") }
        if columnsInfo.columnMapping["c-gene"] != undefined { cols = append(cols, "c-gene") }
        return cols
    }
    keyCols := columnsInfo.clonotypeKeyColumns
    if len(keyCols) == 0 { keyCols = inferKeyColumns() }
    keyComponents := slices.map(keyCols, func(id) { return pt.col(id).fillNull("NA") })
    clonotypeKeyExpr := pt.concatStr(keyComponents, {delimiter: "|"}).hash("sha256", "base64_alphanumeric", 120).alias("clonotypeKey")

    // Filter by chains using V gene prefix
    chainToLocusMap := {
        "IGHeavy": "IGH",
        "IGLight": "IGL", // IGK handled below as well
        "TCRAlpha": "TRA",
        "TCRBeta": "TRB",
        "TCRGamma": "TRG",
        "TCRDelta": "TRD"
    }

    hasCellTags := columnsInfo.cellTagColumns != undefined && len(columnsInfo.cellTagColumns) > 0

    for chain in chains {
        prefix := chainToLocusMap[chain]

        chainDf := undefined
        if chain == "IGLight" {
            chainDf = df.filter(pt.col("v-gene").strSlice(0, 3).eq("IGK").or(pt.col("v-gene").strSlice(0, 3).eq("IGL")))
        } else {
            chainDf = df.filter(pt.col("v-gene").strSlice(0, len(prefix)).eq(prefix))
        }

        // Filter productive
        chainDf = chainDf.filter(pt.col("is-productive"))

        // Length cols
        chainDf = chainDf.withColumns(pt.col("cdr3-aa").strLenChars().alias("cdr3-aa-length"))
        chainDf = chainDf.withColumns(pt.col("cdr3-nt").strLenChars().alias("cdr3-nt-length"))

        chainDf = chainDf.withColumns(clonotypeKeyExpr)

        // Check what abundance data is actually available
        hasUmiCount := columnsInfo.hasUMIs && !is_undefined(columnsInfo.columnMapping["umi-count"])
        hasReadCount := !is_undefined(columnsInfo.columnMapping["read-count"])
        
        // Cast abundance columns - only cast what exists
        // Be robust to potential formatting (e.g., thousand separators) and ensure correct numeric types
        if hasReadCount {
            chainDf = chainDf.withColumns(
                pt.col("read-count").
                    strReplace(",", "", { replaceAll: true }).
                    cast("Float64").
                    fillNull(0).
                    cast("Int64").
                    alias("read-count")
            )
        }
        if hasUmiCount {
            chainDf = chainDf.withColumns(
                pt.col("umi-count").strReplace("[^0-9]", "", { replaceAll: true }).cast("Int64").fillNull(0).alias("umi-count")
            )
        }

        // Export by-cell AFTER filtering by productivity (original MiXCR behavior)
        if hasCellTags {
            // Determine cellKey from tag columns
            cellKeyExpr := undefined
            if len(columnsInfo.cellTagColumns) > 1 {
                cols := slices.map(columnsInfo.cellTagColumns, func(c) { return pt.col(c) })
                cellKeyExpr = pt.concatStr(cols, { delimiter: "#" }).hash("sha256", "base64_alphanumeric", 120)
            } else {
                cellKeyExpr = pt.col(columnsInfo.cellTagColumns[0])
            }
            // Use primary abundance column (prefer UMI if available)
            primaryAbundanceCol := hasUmiCount ? "umi-count" : "read-count"
            byCellDf := chainDf.select(
                cellKeyExpr.alias("cellKey"),
                pt.col("clonotypeKey"),
                pt.col(primaryAbundanceCol).alias(primaryAbundanceCol),
                pt.col("is-productive").alias("is-productive")
            )
            byCellDf.save("byCell-" + chain + ".tsv")
        }

        // Aggregate by clonotype key
        aggregations := []
        
        // Aggregate only the abundance types that actually exist
        if hasReadCount {
            aggregations = append(aggregations, pt.col("read-count").sum().alias("read-count"))
        }
        if hasUmiCount {
            aggregations = append(aggregations, pt.col("umi-count").sum().alias("umi-count"))
        }
        // Use primary abundance column for maxBy (prefer UMI if available)
        primaryAbundanceCol := hasUmiCount ? "umi-count" : "read-count"
        for col in columnsInfo.propertyColumns {
            aggregations = append(aggregations, pt.col(col.column).maxBy(primaryAbundanceCol).alias(col.column))
        }
        chainDf = chainDf.groupBy("clonotypeKey").agg(aggregations...)

        // Generate stats (include only abundance types that exist)
        statsExprs := [
            pt.col("clonotypeKey").count().alias("clonotype-count")
        ]
        if hasReadCount {
            statsExprs = append(statsExprs, pt.col("read-count").sum().alias("read-count"))
        }
        if hasUmiCount {
            statsExprs = append(statsExprs, pt.col("umi-count").sum().alias("umi-count"))
        }
        stats := chainDf.select(statsExprs...)
        stats.saveContent("stats-" + chain + ".tsv")

        // Calculate fractions only for abundance types that exist
        if hasReadCount {
            chainDf = chainDf.withColumns(pt.col("read-count").truediv(pt.col("read-count").sum()).fillNaN(0).alias("read-fraction"))
        }
        if hasUmiCount {
            chainDf = chainDf.withColumns(pt.col("umi-count").truediv(pt.col("umi-count").sum()).fillNaN(0).alias("umi-fraction"))
        }

        // Keep columns (using canonical names) - include all abundance columns, deduping names
        keepColumns := ["clonotypeKey"]
        seenKeep := { "clonotypeKey": true }
        for col in columnsInfo.propertyColumns {
            if !seenKeep[col.column] {
                keepColumns = append(keepColumns, col.column)
                seenKeep[col.column] = true
            }
        }
        for col in columnsInfo.abundanceColumns {
            if !seenKeep[col.column] {
                keepColumns = append(keepColumns, col.column)
                seenKeep[col.column] = true
            }
        }
        chainDf = chainDf.select(keepColumns...)

        chainDf.save(chain + ".tsv")
    }

    wf = wf.run()

    tsv := {}
    stats := {}
    tsvForSingleCell := {}
    for chain in chains {
        tsv[chain] = wf.getFile(chain + ".tsv")
        stats[chain] = wf.getFileContent("stats-" + chain + ".tsv")
        if hasCellTags {
            tsvForSingleCell[chain] = wf.getFile("byCell-" + chain + ".tsv")
        }
    }

    return { tsv: tsv, stats: stats, tsvForSingleCell: tsvForSingleCell }
})


