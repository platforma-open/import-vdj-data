ll := import("@platforma-sdk/workflow-tengo:ll")
self := import("@platforma-sdk/workflow-tengo:tpl.light")
pConstants := import("@platforma-sdk/workflow-tengo:pframes.constants")
smart := import("@platforma-sdk/workflow-tengo:smart")
slices := import("@platforma-sdk/workflow-tengo:slices")
maps := import("@platforma-sdk/workflow-tengo:maps")
assets := import("@platforma-sdk/workflow-tengo:assets")
exec := import("@platforma-sdk/workflow-tengo:exec")
pt := import("@platforma-sdk/workflow-tengo:pt")
sets := import("@platforma-sdk/workflow-tengo:sets")
json := import("json")

self.defineOutputs("tsv", "stats", "tsvForSingleCell")

self.body(func(inputs) {
    inputFiles := inputs[pConstants.VALUE_FIELD_NAME]
    columnsInfo := inputs.columnsInfo
    chains := inputs.chains

    wf := pt.workflow().mem("8GiB").cpu(4)

    dataFrames := []
    for key, file in inputFiles.inputs() {
        dataFrames = append(dataFrames, wf.frame(file, {
            xsvType: "csv",
            id: "table_" + key,
            inferSchema: false
        }))
    }

    if len(dataFrames) == 0 {
        ll.panic("no input files found")
    }

    df := undefined
    if len(dataFrames) > 1 { df = pt.concat(dataFrames) } else { df = dataFrames[0] }

    // Rename original columns to canonical IDs used downstream
    renameExpressions := []
    for canonical, original in columnsInfo.columnMapping {
        if original != undefined {
            // Avoid self-alias which can create duplicate column names
            if canonical != original {
                renameExpressions = append(renameExpressions, pt.col(original).alias(canonical))
            }
        }
    }
    df = df.withColumns(renameExpressions...)

    // Add vdj aa and nt columns if present in columnsInfo.propertyColumns
    hasFr4Nt := columnsInfo.columnMapping["fr4-nt"] != undefined
    hasFr4Aa := columnsInfo.columnMapping["fr4-aa"] != undefined
    hasVdjNt := columnsInfo.columnMapping["vdj-nt"] != undefined
    hasVdjAa := columnsInfo.columnMapping["vdj-aa"] != undefined
    nt_cols := ["fr1-nt", "cdr1-nt", "fr2-nt", "cdr2-nt", "fr3-nt", "cdr3-nt"]
    if hasFr4Nt { nt_cols = append(nt_cols, "fr4-nt") }
    aa_cols := ["fr1-aa", "cdr1-aa", "fr2-aa", "cdr2-aa", "fr3-aa", "cdr3-aa"]
    if hasFr4Aa { aa_cols = append(aa_cols, "fr4-aa") }

    for prop in columnsInfo.propertyColumns {
        isVdjNt := false
        isVdjAa := false
        if prop.spec != undefined && prop.spec.domain != undefined {
            isVdjNt = prop.spec.domain["pl7.app/vdj/feature"] == "VDJRegion"
            isVdjAa = prop.spec.domain["pl7.app/vdj/feature"] == "VDJRegionInFrame"
        }

        if isVdjNt && !hasVdjNt {
            nt_exprs := slices.map(nt_cols, func(c) { return pt.col(c) })
            df = df.withColumns(pt.concatStr(nt_exprs, { delimiter: "" }).alias(prop.column))
        }
        if isVdjAa && !hasVdjAa {
            aa_exprs := slices.map(aa_cols, func(c) { return pt.col(c) })
            df = df.withColumns(pt.concatStr(aa_exprs, { delimiter: "" }).alias(prop.column))
        }
    }

    // Remove rows where any sequence column contains "region_not_covered"
    seqCols := nt_cols + aa_cols + ["vdj-nt", "vdj-aa"]
    invalidExpr := undefined
    for col in seqCols {
        if columnsInfo.columnMapping[col] != undefined {
            cond := pt.col(col).strContains("region_not_covered", { literal: true })
            if invalidExpr == undefined { invalidExpr = cond } else { invalidExpr = invalidExpr.or(cond) }
        }
    }
    if invalidExpr != undefined {
        df = df.filter(invalidExpr.not())
    }

    // Cell Ranger doesn't provide allele calls; skip any allele synthesis

    // Cell Ranger already provides direct v/d/j/c gene columns; no best-hit/allele derivation needed

    // Drop rows with empty v/j genes
    for col in ["j-gene", "v-gene"] {
        df = df.filter(pt.col(col).isNotNull().and(pt.col(col).neq("")))
    }

    // Productivity is always present in Cell Ranger as boolean (true/false)

    // Build clonotypeKey
    keyComponents := slices.map(columnsInfo.clonotypeKeyColumns, func(id) { return pt.col(id).fillNull("NA") })
    clonotypeKeyExpr := pt.concatStr(keyComponents, {delimiter: "|"}).hash("sha256", "base64_alphanumeric", 120).alias("clonotypeKey")

    // Filter by chains using V gene prefix
    chainToLocusMap := {
        "IGHeavy": "IGH",
        "IGLight": "IGL",
        "TCRAlpha": "TRA",
        "TCRBeta": "TRB",
        "TCRGamma": "TRG",
        "TCRDelta": "TRD"
    }

    hasCellTags := columnsInfo.cellTagColumns != undefined && len(columnsInfo.cellTagColumns) > 0

    for chain in chains {
        prefix := chainToLocusMap[chain]

        chainDf := undefined
        if chain == "IGLight" {
            chainDf = df.filter(pt.col("v-gene").strSlice(0, 3).eq("IGK").or(pt.col("v-gene").strSlice(0, 3).eq("IGL")))
        } else {
            chainDf = df.filter(pt.col("v-gene").strSlice(0, len(prefix)).eq(prefix))
        }

        // Check what abundance data is actually available and cast early
        hasUmiCount := columnsInfo.hasUMIs && !is_undefined(columnsInfo.columnMapping["umi-count"])
        hasReadCount := !is_undefined(columnsInfo.columnMapping["read-count"])
        if hasReadCount {
            chainDf = chainDf.withColumns(
                pt.col("read-count").
                    strReplace(",", "", { replaceAll: true }).
                    cast("Float64").
                    fillNull(0).
                    cast("Int64").
                    alias("read-count")
            )
        }
        if hasUmiCount {
            chainDf = chainDf.withColumns(
                pt.col("umi-count").strReplace("[^0-9]", "", { replaceAll: true }).cast("Int64").fillNull(0).alias("umi-count")
            )
        }

        // Add clonotype key before by-cell export
        chainDf = chainDf.withColumns(clonotypeKeyExpr)

        // Export by-cell BEFORE filtering by productivity to avoid losing chain info
        if hasCellTags {
            // Use the detected tag column; strip trailing '-<digits>'
            tagCol := columnsInfo.cellTagColumns[0]
            cellKeyExpr := pt.col(tagCol).strReplace("-[0-9]+$", "", { replaceAll: true })
            // Cell Ranger always has UMIs; use UMIs as primary abundance
            primaryAbundanceCol := "umi-count"
            byCellDf := chainDf.select(
                cellKeyExpr.alias("cellKey"),
                pt.col("clonotypeKey"),
                pt.col(primaryAbundanceCol).alias(primaryAbundanceCol),
                pt.col("is-productive").alias("is-productive")
            )
            byCellDf.save("byCell-" + chain + ".tsv")
        }

        // Filter productive (Cell Ranger stores as string "true"/"false")
        chainDf = chainDf.filter(pt.col("is-productive").eq("true"))

        // Length cols
        chainDf = chainDf.withColumns(pt.col("cdr3-aa").strLenChars().alias("cdr3-aa-length"))
        chainDf = chainDf.withColumns(pt.col("cdr3-nt").strLenChars().alias("cdr3-nt-length"))

        // (by-cell save moved before productivity filter)

        aggregations := []
        if hasReadCount { aggregations = append(aggregations, pt.col("read-count").sum().alias("read-count")) }
        if hasUmiCount { aggregations = append(aggregations, pt.col("umi-count").sum().alias("umi-count")) }
        // Cell Ranger: UMIs are primary for aggregation
        primaryAbundanceCol := "umi-count"
        for col in columnsInfo.propertyColumns {
            aggregations = append(aggregations, pt.col(col.column).maxBy(primaryAbundanceCol).alias(col.column))
        }
        chainDf = chainDf.groupBy("clonotypeKey").agg(aggregations...)

        statsExprs := [ pt.col("clonotypeKey").count().alias("clonotype-count") ]
        if hasReadCount { statsExprs = append(statsExprs, pt.col("read-count").sum().alias("read-count")) }
        if hasUmiCount { statsExprs = append(statsExprs, pt.col("umi-count").sum().alias("umi-count")) }
        stats := chainDf.select(statsExprs...)
        stats.saveContent("stats-" + chain + ".tsv")

        if hasReadCount { chainDf = chainDf.withColumns(pt.col("read-count").truediv(pt.col("read-count").sum()).fillNaN(0).alias("read-fraction")) }
        if hasUmiCount { chainDf = chainDf.withColumns(pt.col("umi-count").truediv(pt.col("umi-count").sum()).fillNaN(0).alias("umi-fraction")) }

        keepColumns := ["clonotypeKey"]
        seenKeep := { "clonotypeKey": true }
        for col in columnsInfo.propertyColumns {
            if !seenKeep[col.column] { keepColumns = append(keepColumns, col.column); seenKeep[col.column] = true }
        }
        for col in columnsInfo.abundanceColumns {
            if !seenKeep[col.column] { keepColumns = append(keepColumns, col.column); seenKeep[col.column] = true }
        }
        chainDf = chainDf.select(keepColumns...)

        chainDf.save(chain + ".tsv")
    }

    wf = wf.run()

    tsv := {}
    stats := {}
    tsvForSingleCell := {}
    for chain in chains {
        tsv[chain] = wf.getFile(chain + ".tsv")
        stats[chain] = wf.getFileContent("stats-" + chain + ".tsv")
        if hasCellTags { tsvForSingleCell[chain] = wf.getFile("byCell-" + chain + ".tsv") }
    }

    return { tsv: tsv, stats: stats, tsvForSingleCell: tsvForSingleCell }
})



