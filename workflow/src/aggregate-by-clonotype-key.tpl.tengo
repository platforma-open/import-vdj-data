ll := import("@platforma-sdk/workflow-tengo:ll")
self := import("@platforma-sdk/workflow-tengo:tpl")
pConstants := import("@platforma-sdk/workflow-tengo:pframes.constants")
slices := import("@platforma-sdk/workflow-tengo:slices")
maps := import("@platforma-sdk/workflow-tengo:maps")
units := import("@platforma-sdk/workflow-tengo:units")
clonotypeLabel := import(":clonotype-label")
pt := import("@platforma-sdk/workflow-tengo:pt")
math := import("math")

json := import("json")

self.defineOutputs("tsv")

self.body(func(inputs) {
	inputData := inputs[pConstants.VALUE_FIELD_NAME]
	inputDataMeta := inputData.getDataAsJson()

	// ll.assert(inputDataMeta.keyLength == 1, "unexpected number of aggregation axes")

	primaryAbundance := inputs.primaryAbundance
	primaryFraction := inputs.primaryFraction

	// { column: string; type: string }
	schema := inputs.schema

	inputMap := inputData.inputs()
	numberOfSamples := len(inputMap)

	wf := pt.workflow().
		inMediumQueue().
		mem(int(math.max(numberOfSamples, 64)) * units.GiB).
		cpu(int(math.max(numberOfSamples, 32)))

	dataFrames := []

	// Determine the correct type for primary abundance
	// UMI counts can be fractional in ImmunoSeq (estimated genome counts), while read counts are always integers
	primaryAbundanceType := primaryAbundance == "umi-count" ? "Float64" : "Int64"

	for sKey in maps.getKeys(inputMap) {
		inputFile := inputMap[sKey]
		key := json.decode(sKey)
		if len(key) != 1 {
			ll.panic("malformed key: %v", sKey)
		}
		sampleId := key[0]
		dfId := "table_" + sampleId

		df := wf.frame({
			file: inputFile,
			xsvType: "tsv"
		}, {
			id: dfId,
			inferSchema: false // Reading all as strings, casting to numeric types below
		})
		dataFrames = append(dataFrames, df)
	}

	currentDf := undefined
	if len(dataFrames) == 0 {
		ll.panic("no input files found")
	} else if len(dataFrames) == 1 {
		currentDf = dataFrames[0]
	} else {
		currentDf = pt.concat(dataFrames)
	}

	currentDf = currentDf.withColumns(pt.col(primaryAbundance).cast(primaryAbundanceType, {strict: true}).alias(primaryAbundance))
	currentDf = currentDf.withColumns(pt.col(primaryFraction).cast("Double", {strict: true}).alias(primaryFraction))

	aggExpressions := []


	for colDef in schema {
		if colDef.column == "clonotypeLabel" || colDef.column == "sampleCount" {
		 	continue
		 }
		aggExpressions = append(aggExpressions,
			pt.col(colDef.column).maxBy(pt.col(primaryAbundance)).alias(colDef.column)
		)
	}

	aggExpressions = append(aggExpressions,
		pt.col(primaryAbundance).count().alias("sampleCount"),
		pt.col(primaryFraction).mean().alias(primaryFraction + "-mean"),
		pt.col(primaryAbundance).sum().alias(primaryAbundance + "-total")
	)

	aggregatedDf := currentDf.groupBy("clonotypeKey").agg(aggExpressions...)
	aggregatedDf = clonotypeLabel.addClonotypeLabelColumnsPt(aggregatedDf, "clonotypeKey", "clonotypeLabel", pt)
	aggregatedDf.save("output.tsv")

	wfResult := wf.run()

	return {
		tsv: wfResult.getFile("output.tsv")
	}
})
