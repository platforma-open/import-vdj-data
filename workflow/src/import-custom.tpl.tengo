ll := import("@platforma-sdk/workflow-tengo:ll")
self := import("@platforma-sdk/workflow-tengo:tpl.light")
pConstants := import("@platforma-sdk/workflow-tengo:pframes.constants")
slices := import("@platforma-sdk/workflow-tengo:slices")
pt := import("@platforma-sdk/workflow-tengo:pt")

self.defineOutputs("tsv", "stats")

self.body(func(inputs) {
    inputFiles := inputs[pConstants.VALUE_FIELD_NAME]
    columnsInfo := inputs.columnsInfo
    chains := inputs.chains

    wf := pt.workflow().mem("8GiB").cpu(4)

    dataFrames := []
    for key, file in inputFiles.inputs() {
        dataFrames = append(dataFrames, wf.frame(file, {
            xsvType: "tsv",
            id: "table_" + key,
            // MiXCR files can have mixed types (strings in columns with floats)
			inferSchema: false
        }))
    }

    if len(dataFrames) == 0 {
        ll.panic("no input files found")
    }

    df := pt.concat(dataFrames)

    // Rename original columns to canonical IDs
    renameExpressions := []
    for canonical, original in columnsInfo.columnMapping {
        renameExpressions = append(renameExpressions, pt.col(original).alias(canonical))
    }
    df = df.withColumns(renameExpressions...)

    // For MiXCR/similar formats we might need to remove extra content from gene columns
    geneColumns := ["v-gene", "j-gene", "d-gene", "c-gene"]
    stripAllele := func(expr) { return expr.strReplace("\\*.*$", "", { replaceAll: true }) }
    for col in geneColumns {
        if columnsInfo.columnMapping[col] != undefined {
            df = df.withColumns(stripAllele(pt.col(col)).alias(col))
        }
    }

    // Basic row filters: require V and J genes to be present
    for col in ["j-gene", "v-gene"] {
        df = df.filter(pt.col(col).isNotNull().and(pt.col(col).neq("")))
    }

    keyComponents := slices.map(columnsInfo.clonotypeKeyColumns, func(id) { return pt.col(id).fillNull("NA") })

    clonotypeKeyExpr := pt.
        concatStr(keyComponents, { delimiter: "|" }).
        hash("sha256", "base64_alphanumeric", 120).
        alias("clonotypeKey")

    hasUMIs := columnsInfo.hasUMIs
    hasReads := columnsInfo.columnMapping["read-count"] != undefined
    hasAA := columnsInfo.columnMapping["cdr3-aa"] != undefined
    hasNT := columnsInfo.columnMapping["cdr3-nt"] != undefined
    hasTopChains := columnsInfo.columnMapping["top-chains"] != undefined

    // Add vdj aa and nt columns if present in columnsInfo.propertyColumns
    hasFr4Nt := columnsInfo.columnMapping["fr4-nt"] != undefined
    hasFr4Aa := columnsInfo.columnMapping["fr4-aa"] != undefined
    hasVdjNt := columnsInfo.columnMapping["vdj-nt"] != undefined
    hasVdjAa := columnsInfo.columnMapping["vdj-aa"] != undefined

    nt_cols := ["fr1-nt", "cdr1-nt", "fr2-nt", "cdr2-nt", "fr3-nt", "cdr3-nt"]
    if hasFr4Nt { nt_cols = append(nt_cols, "fr4-nt") }
    aa_cols := ["fr1-aa", "cdr1-aa", "fr2-aa", "cdr2-aa", "fr3-aa", "cdr3-aa"]
    if hasFr4Aa { aa_cols = append(aa_cols, "fr4-aa") }

    for prop in columnsInfo.propertyColumns {
        isVdjNt := false
        isVdjAa := false
        if prop.spec != undefined && prop.spec.domain != undefined {
            isVdjNt = prop.spec.domain["pl7.app/vdj/feature"] == "VDJRegion"
            isVdjAa = prop.spec.domain["pl7.app/vdj/feature"] == "VDJRegionInFrame"
        }

        if isVdjNt && !hasVdjNt {
            nt_exprs := slices.map(nt_cols, func(c) { return pt.col(c) })
            df = df.withColumns(pt.concatStr(nt_exprs, { delimiter: "" }).alias(prop.column))
        }
        if isVdjAa && !hasVdjAa {
            aa_exprs := slices.map(aa_cols, func(c) { return pt.col(c) })
            df = df.withColumns(pt.concatStr(aa_exprs, { delimiter: "" }).alias(prop.column))
        }
    }

    // Remove rows where any sequence column contains "region_not_covered"
    seqCols := nt_cols + aa_cols + ["vdj-nt", "vdj-aa"]
    invalidExpr := undefined
    for col in seqCols {
        if columnsInfo.columnMapping[col] != undefined {
            cond := pt.col(col).strContains("region_not_covered", { literal: true })
            if invalidExpr == undefined { invalidExpr = cond } else { invalidExpr = invalidExpr.or(cond) }
        }
    }
    if invalidExpr != undefined {
        df = df.filter(invalidExpr.not())
    }

    // Convert numeric columns to a numeric type (We also remove floating points if present)
    if hasReads {
        castExpressions := [
            pt.col("read-count").strReplace("\\..*", "").cast("Int64").alias("read-count")
        ]
        df = df.withColumns(castExpressions...)
    }
    if hasUMIs {
        castExpressions := [
            pt.col("umi-count").cast("Float64").alias("umi-count")
        ]
        df = df.withColumns(castExpressions...)
    }

    // Determine primary abundance
    primaryAbundance := hasUMIs ? "umi-count" : "read-count"
    if inputs.primaryCountType != undefined {
        primaryAbundance = inputs.primaryCountType == "umi" ? "umi-count" : "read-count"
    }

    chainToLocusMap := {
        "IGHeavy":["IGH"],
        "IGLight": "IGL", // Default to IGL, IGK is handled below
        "TCRAlpha": ["TCRA", "TRAC", "TRA"],
        "TCRBeta": ["TCRB", "TRBC", "TRB"],
        "TCRGamma": ["TCRG", "TRGC", "TRG"],
        "TCRDelta": ["TCRD", "TRDC", "TRD"]
    }

    chainColumn := hasTopChains ? "top-chains" : "v-gene"
    for chain in chains {
        prefixes := chainToLocusMap[chain]

        chainDf := undefined
        if chain == "IGLight" {
            chainDf = df.filter(
                pt.col(chainColumn).strSlice(0, 3).eq("IGK").or(pt.col(chainColumn).strSlice(0, 3).eq("IGL"))
            )
        } else {
            filterExpr := undefined
            for i := 0; i < len(prefixes); i++ {
                prefix := prefixes[i]
                expr := pt.col(chainColumn).strSlice(0, len(prefix)).eq(prefix)
                if i == 0 {
                    filterExpr = expr
                } else {
                    filterExpr = filterExpr.or(expr)
                }
            }
            chainDf = df.filter(filterExpr)
        }

        // If cdr3-aa provided, compute productivity and filter to productive
        if hasAA {
            chainDf = chainDf.withColumns(
                pt.col("cdr3-aa").isNotNull().
                    and(pt.col("cdr3-aa").neq("")).
                    and(pt.col("cdr3-aa").strContains("*", { literal: true }).not()).
                    and(pt.col("cdr3-aa").strContains("_", { literal: true }).not()).
                    alias("is-productive")
            )
            chainDf = chainDf.filter(pt.col("is-productive"))
        }

        // Derive lengths if available
        if hasAA {
            chainDf = chainDf.withColumns(pt.col("cdr3-aa").strLenChars().alias("cdr3-aa-length"))
        }
        if hasNT {
            chainDf = chainDf.withColumns(pt.col("cdr3-nt").strLenChars().alias("cdr3-nt-length"))
        }

        chainDf = chainDf.withColumns(clonotypeKeyExpr)

        // Cast abundance columns present
        // Read counts are always integers, but UMI counts can be fractional (e.g., ImmunoSeq estimated genome counts)
        if hasUMIs {
            chainDf = chainDf.withColumns(pt.col("umi-count").cast("Float64").alias("umi-count"))
        }
        if hasReads {
            chainDf = chainDf.withColumns(pt.col("read-count").cast("Int64").alias("read-count"))
        }

        // Aggregate by clonotypeKey using whichever abundance exists
        aggregations := []
        if hasReads {
            aggregations = append(aggregations, pt.col("read-count").sum().alias("read-count"))
        }
        if hasUMIs {
            aggregations = append(aggregations, pt.col("umi-count").sum().alias("umi-count"))
        }
        for col in columnsInfo.propertyColumns {
            aggregations = append(aggregations, pt.col(col.column).maxBy(primaryAbundance).alias(col.column))
        }
        chainDf = chainDf.groupBy("clonotypeKey").agg(aggregations...)

        // Fractions if the corresponding counts present
        if hasReads {
            chainDf = chainDf.withColumns(pt.col("read-count").truediv(pt.col("read-count").sum()).fillNaN(0).alias("read-fraction"))
        }
        if hasUMIs {
            chainDf = chainDf.withColumns(pt.col("umi-count").truediv(pt.col("umi-count").sum()).fillNaN(0).alias("umi-fraction"))
        }

        // Keep property and abundance columns
        keepColumns := ["clonotypeKey"]
        for col in columnsInfo.propertyColumns {
            keepColumns = append(keepColumns, col.column) 
        }
        for col in columnsInfo.abundanceColumns {
            keepColumns = append(keepColumns, col.column)
        }
        chainDf = chainDf.select(keepColumns...)

        chainDf.save(chain + ".tsv")

        statsExprs := [ pt.col("clonotypeKey").count().alias("clonotype-count") ]
        if hasReads {
            statsExprs = append(statsExprs, pt.col("read-count").sum().alias("read-count"))
        }
        if hasUMIs {
            statsExprs = append(statsExprs, pt.col("umi-count").sum().alias("umi-count"))
        }
        stats := chainDf.select(statsExprs...)
        stats.saveContent("stats-" + chain + ".tsv")
    }

    wf = wf.run()

    tsv := {}
    stats := {}
    for chain in chains {
        tsv[chain] = wf.getFile(chain + ".tsv")
        stats[chain] = wf.getFileContent("stats-" + chain + ".tsv")
    }

    return {
        tsv: tsv,
        stats: stats
    }
}) 